---
title: "The NYC Rat Index"
author: "Bertrand Wilden"
date: "2023-06-21"
categories: [Bayes, GIS]
max-description-length: 20
draft: true
---

Rats are "public enemy number one"---at least so says New York City Mayor Eric Adams. Last year the city established a ["Rat Czar"](https://www.nyc.gov/office-of-the-mayor/news/249-23/mayor-adams-anoints-kathleen-corradi-nyc-s-first-ever-rat-czar-#/0) who has been tasked with detecting and exterminating rat populations across the five boroughs. While I respect the lives all creatures great and small, mapping out the concentration of rats in the city seems like a worthwhile public service. With this goal in mind, introduce the all-new **NYC Rat Index**.

[Discuss method/R overview]

```{r}
#| message: false
#| warning: false
# Packages used:
library(dplyr)
library(tidyr)
library(tidycensus)
library(ggplot2)
library(MetBrewer)
library(spdep)
library(sf)
library(INLA)
library(leaflet)
```

```{css, echo=FALSE}
.title {
  color: #f5f5f5;
}
```

# Rat Data

The data I use to construct the **Rat Index** come from the [https://data.cityofnewyork.us/Health/Rodent-Inspection/p937-wjvj/about_data](NYC Rat Information Portal (RIP)).

```{r}
rats <- readr::read_csv("https://data.cityofnewyork.us/resource/p937-wjvj.csv?$limit=2500000")
```

Each of the 2.5 million observations is a rodent inspection from the year 2010 to present. A lot of inspections don't find evidence of rats, so I focus on only the rows where `result == "Rat Activity"`. Mapping rat populations with this data is a bit problematic because there is probably some bias inherent in inspection rates. The RIP discusses this in their disclaimer:

> Notes on data limitations: Please note that if a property/taxlot does not appear in the file, that does not indicate an absence of rats - rather just that it has not been inspected. Similarly, neighborhoods with higher numbers properties with active rat signs may not actually have higher rat populations but simply have more inspections.

I will attempt to deal with this bias by building a geospatial model of rat activity---rather than by simply using the raw data on its own. The idea here is that we can infer rat activity in areas with low inspection rates by how proximate they are to areas with high rat activity/inspection rates in the data. If there's one thing I know about rats it's that they love scurrying around from place to place.

```{r}
rats_zip <- rats |> 
  mutate(year = lubridate::year(inspection_date)) |> 
  summarise(n_rats = sum(result == "Rat Activity", na.rm = TRUE),
            .by = c("zip_code", "borough", "boro_code", "year")) |> 
  # removing some invalid rows
  filter(!is.na(borough), zip_code != "0", year %in% 2016:2021)
```

Let's start by creating a new data frame, `rats_zip`, which collapses the number of rat activity observations (`n_rats`) down to the ZIP code-year level. I chose ZIP code as the level of spatial aggregation because most people know which ZIP code they live in (as opposed to Census tract or other designation). This will make it easier to know the **Rat Index** value where you live. The downside of using ZIP codes, however, is that they are constructed to facilitate mail delivery---not balanced geospatial analysis. In Manhattan, [https://convene.com/catalyst/office/buildings-new-york-city-own-zip-code/](42 *buildings*) have their own ZIP code. 

```{r}
#| message: false
nyc_zips <- get_acs(
  geography = "zcta",
  variables = c("n_kitchens" = "B25051_002",
                "n_food_workers" = "C24050_040",
                "buildings_before_1939" = "B25034_011",
                "total_population" = "B01003_001"),
  year = 2021,
  survey = "acs5",
  geometry = TRUE,
  output = "wide",
  progress = FALSE
) |> 
  mutate(zip_code = as.numeric(GEOID)) |> 
  filter(zip_code %in% rats_zip$zip_code)

# Merge the ZIP data in with the rats data
rats_zip <- rats_zip |> 
  inner_join(nyc_zips, by = "zip_code") |> 
         # some ZIPs got put in the wrong borough
  mutate(borough = case_when(zip_code == 10463 ~ "Bronx",
                             zip_code == 10451 ~ "Bronx",
                             zip_code == 11370 ~ "Queens",
                             zip_code == 11207 ~ "Brooklyn",
                             .default = borough),
         # model functions like data to be indexed as 1, 2, 3, etc
         zip_code_code = as.integer(as.factor(zip_code)),
         year_code = as.integer(as.factor(year)))
```

We will grab ZIP code spatial geometries, as well as some model covariates, using the **tidycensus** R package. These covariates are variables from the Census American Community Survey (ACS) which I believe can help predict rat activity. Because most of my knowledge about rat psychology comes from the movie Ratatouille, the number of kitchens and the number of food workers (e.g. chefs) seemed like they would be very important. The number of old buildings (built before 1939) in a ZIP code also seems relevant. I envision rats having an easier time scurrying around and infiltrating older buildings compared to new ones. And lastly we'll use the total population variable because apparently rats like living near us humans.

## Geospatial Wrangling

In addition to the outcome variable, `n_rats`, and the Census covariates we will use to predict rat activity, the `rats_zip` data frame has a `geometry` variable containing the spatial polygon information for each ZIP code. These geometries can be used to build a neighbor adjacency graph which we will need for our spatial model later. To infer rat activity from proximate ZIP codes, we need to know which ZIP codes are neighbors.

```{r}
# Using only zip codes, boroughs, and geometry to illustrate the neighbor graph
zips_only <- rats_zip |> 
  st_as_sf() |> 
  select(zip_code, borough) |> 
  distinct()

# Neighbor adjacency graph
zips_adj <- poly2nb(zips_only)
```

The function `poly2nb()` from the **spdep** package takes our data with spatial geometry and returns a neighbor adjacency graph. We could take a look at this graph using the base `plot(zips_adj)` function, but I prefer the look and flexibility of ggplot

```{r}
nb_to_sf <- function(nb_obj, sf_obj) {
  sf_out <- as(nb2lines(nb_obj, coords = coordinates(as_Spatial(sf_obj))), "sf") |> 
    st_set_crs(st_crs(sf_obj))
  return(sf_out)
}
```

The function `nb_to_sf()` can be used to convert `zips_adj` back into an `sf` data object which plays nicely with ggplot functions.[^1]

[^1]: Code adapted from Maxwell B. Joseph https://mbjoseph.github.io/posts/2018-12-27-plotting-spatial-neighbors-in-ggplot2/


```{r}
#| warning: false
ggplot(zips_only) +
  geom_sf(color = 'white', aes(fill = borough)) +
  geom_sf(data = nb_to_sf(zips_adj, zips_only)) +
  scale_fill_manual(values = met.brewer("Hokusai3")) + 
  theme_void()
```

And here is our beautiful NYC ZIP code adjacency graph! Unfortunately for us, however, the `poly2nb()` function only connected ZIP codes if they were terrestrial neighbors. This leaves all the boroughs except Brooklyn and Queens disconnected from one another. Rockaway beach area is also isolated from the rest of the city, and poor Roosevelt Island is all alone with zero neighbors. We need to do some adjustments if we want to properly model rat activity. While I'm not sure whether a rat could swim across the East River from Manhattan to Brooklyn, I have first hand knowledge of them scurrying on the city's various tunnels and bridges.

```{r}
add_neighbors <- function(nb_obj, links, node_vec) {
  for (i in seq_along(links)) {
    nb_obj[[match(names(links[i]), node_vec)]] <- setdiff(as.integer(sort(c(nb_obj[[match(names(links[i]), node_vec)]], match(links[i], node_vec)))), 0)
    nb_obj[[match(links[i], node_vec)]] <- setdiff(as.integer(sort(c(nb_obj[[match(links[i], node_vec)]], match(names(links[i]), node_vec)))), 0)
  }
  return(nb_obj)
}
```

It turns out that adding manual connections to a `nb` spatial neighbors object is extremely annoying. The **spdep** package supposedly has a function for this: `edit.nb()`, but you will get an error saying "do not use in RStudio" (???). I refuse to work out of the Console like a caveman, so instead I wrote a function `add_neighbors()` to help with this. Enter your original `nb` spatial neighbors object, a vector of neighbor pairs you wish to connect, and the geography variable from the data frame you used to create the `nb` object---and you will get out a new `nb` spatial neighbors object with all those nodes connected. The `links` argument in this example will be ZIP code pairs and the `node_vec` argument will be the ZIP code column in `zips_only`, but `add_neighbors()` will also work if you want to connect Census tracts or any other geographic unit.

```{r}
connect_nyc_neighbor_zips <- purrr::partial(
  add_neighbors,
  links = c("11414" = "11693", # Cross Bay Blvd
            "11234" = "11697", # Marine Parkway Bridge
            "10305" = "11209", # Verrazzano Bridge
            "10004" = "11231", # Brooklyn-Battery Tunnel
            "10038" = "11201", # Brooklyn Bridge
            "10002" = "11201", # Manhattan Bridge
            "10002" = "11211", # Williamsburg Bridge
            "10017" = "11109", # Queens-Midtown Tunnel
            "10022" = "11101", # Queensboro Bridge
            "10044" = "11106", # Roosevelt Island Bridge
            "10035" = "11102", # Triborough Bridge
            "10035" = "10454", # Triborough Bridge
            "10037" = "10451", # Madison Ave. Bridge
            "10039" = "10451", # 145th St. Bridge
            "10033" = "10453", # Washington Bridge
            "10034" = "10468", # University Heights Bridge
            "10034" = "10463", # Broadway Bridge
            "10465" = "11360", # Throgs Neck Bridge
            "10465" = "11357") # Whitestone Bridge
)
```

Because I will use `add_neighbors()` multiple times in this project, I created a `purrr::partial()` version of it with the major NYC bridges and tunnels connected by default. Now I know what some of you are thinking. What about the *SUBWAY*?! Rats *LOVE* the *SUBWAY*! Sorry, but it was tedious enough looking up all these bridges. A serious GIS specialist could probably do something fancy like overlay a shapefile of the NYC subway system on top of the ZIP code shapefile, and add connections that way. But for now we will just assume that rats are banned from riding the subway.

```{r}
zips_adj_c <- zips_adj |> 
  connect_nyc_neighbor_zips(node_vec = zips_only$zip_code)
```

With that caveat out of the way let's create a new spatial neighbor object, `zips_adj_c`, with the ZIP codes that we want connected. 

```{r}
#| warning: false
ggplot(zips_only) +
  geom_sf(color = "white", aes(fill = borough)) +
  geom_sf(data = nb_to_sf(zips_adj_c, zips_only), color = "red") +
  geom_sf(data = nb_to_sf(zips_adj, zips_only)) +
  scale_fill_manual(values = met.brewer("Hokusai3")) + 
  theme_void()
```

Plotting these two graphs on top of each other confirms that we fully connected the entire city! The rats are now free to roam from borough to borough in our model.

Speaking of the model, let's return to the ZIP-year level data, `rats_zip`, we created earlier. 

```{r}
zips_adj_long <- rats_zip |> 
  st_as_sf() |> 
  poly2nb() |> 
  connect_nyc_neighbor_zips(node_vec = rats_zip$zip_code)

zip_mat <- nb2mat(zips_adj_long, style = "B") 
```

We'll create an `nb` spatial neighbor object from this long data using `poly2nb()` as before, and add the tunnel and bridge connections using `connect_nyc_neighbor_zips()`.  We will then encode the neighbor relations in `zips_adj_long` as an adjacency matrix using `nb2mat()` with `style = "B"` for "binary". This creates a square matrix of 1's and 0's where the 1's denote adjacency between ZIP codes. 

```{r}
rat_mod = inla(
  n_rats ~ total_populationE + buildings_before_1939E + n_kitchensE + n_food_workersE +
    f(zip_code_code, model = "bym2", graph = zip_mat),
  data = rats_zip,
  family = "poisson"
)
```

Time to build the rat model. We'll use the [**INLA**](https://www.r-inla.org/home) package to predict rat activity given the population, building age, kitchens, and food worker variables we assembled earlier. I am relatively new to using **INLA**, but it seems to be very popular for fitting Bayesian models with spatial components. It uses a form of approximate Bayesian inference called **I**tegrated **N**ested **L**aplace **A**pproximation, which means it runs a lot faster than full Markov Chain Monte Carlo samplers such as [Stan](https://mc-stan.org/). 

The `f(zip_code_code, model = "bym", graph = zip_mat)` section in the model is the spatial component, aka the component that allows neighboring ZIP codes to share rat information with each other. **INLA** and all the spatial functions we used in **spdep** (`poly2nb()` and `nb2mat()`) are kind of old-school when it comes to their reliance on integer indexing---as opposed to allowing ZIP codes to be their true, un-ordered, selves. This is why I use the variable `zip_code_code` instead of `zip_code` here. It contains integer values matching each ZIP code with its position in the `nb` spatial neighbor object. The `model = "bym2"` part tells **INLA** we are doing spatial analyses using the [Besag-York-MolliÃ© method](https://mc-stan.org/users/documentation/case-studies/icar_stan.html#bigger-data-from-56-counties-in-scotland-to-1921-census-tracts-in-new-york-city). BYM2 gives each ZIP code a varying intercept (i.e. "random effect") which is a combination of spatial correlation with its neighboring ZIP codes and an unstructured effect for non-spatial rat behavior.

We're using `family = "poisson"` in the model because the outcome variable, `n_rats`, is a count of rat inspections and Poisson likelihoods are good for count data.[^2]

[^2]: Note: no rats were poissoned during the fitting of this model.

```{r}
rats_zip$rat_score = rat_mod$summary.fitted.values$mode

rats_zip <- rats_zip |> 
  mutate(log_rat_score = log10(rat_score)) |> 
  mutate(zip_rat_rank = as.integer(as.factor(log_rat_score)),
         zip_rat_perc = percent_rank(zip_rat_rank))
```



```{r}
rats_zip |> 
  st_as_sf() |> 
  ggplot(aes(fill = log_rat_score)) +
  geom_sf() + 
  scale_fill_viridis_c(option = "B", 
                       # labels = function(x) round(x^10, 2),
                       # breaks = log(c(1, 10, 100))
                       ) +
  theme_void()
```

```{r}
l <- st_as_sf(rats_zip) |> 
  leaflet() |> 
  addTiles()

labels <- sprintf(
  "<strong> ZIP Code: %s </strong> <br/>
  Rat Index: %s <br/> Percentile: %s",
  rats_zip$zip_code, 
  round(rats_zip$log_rat_score, 2),
  round(rats_zip$zip_rat_perc, 3)
) %>%
  lapply(htmltools::HTML)

pal <- colorNumeric(
  palette = "plasma",
  domain = rats_zip$log_mode
  )

l |> 
  addPolygons(
    smoothFactor = 0.2, fillOpacity = .5,
    fillColor = ~pal(log_mode),
    weight = .1,
    highlightOptions = highlightOptions(weight = 4, color = "white"),
    label = labels,
    labelOptions = labelOptions(
      style = list(
        "font-weight" = "normal",
        padding = "3px 8px"
      ),
      textsize = "15px", direction = "auto"
    )
  ) |> 
  addLegend(
    pal = pal, values = ~log_mode, opacity = 1,
    title = "Rat Index", position = "bottomright"
  )
```
